import requests
import os
import time
import re
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import gc
from tqdm import tqdm
import psutil
import sys

class WallhavenBatchDownloader:
    def __init__(self, txt_file="wallhaven_links.txt", save_dir="batch_download", max_workers=4):
        self.txt_file = txt_file
        self.save_dir = save_dir
        self.max_workers = max_workers
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        self.success_count = 0
        self.fail_count = 0
        self.lock = threading.Lock()
    
    def load_links(self):
        """è¯»å–TXTæ–‡ä»¶é“¾æ¥ - è‡ªåŠ¨è§£æå„ç§æ ¼å¼"""
        if not os.path.exists(self.txt_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {self.txt_file}")
            return []
        
        # æ”¯æŒ4ç§æ ¼å¼è‡ªåŠ¨è§£æ
        patterns = [
            r'https://wallhaven\.cc/w/[a-z0-9]{6}',  # çº¯é“¾æ¥
            r'\[https://wallhaven\.cc/w/[a-z0-9]{6}\]',  # [é“¾æ¥]
            r'\(https://wallhaven\.cc/w/[a-z0-9]{6}\)',  # (é“¾æ¥)
            r'https://wallhaven\.cc/w/[a-z0-9]{6}[)\]]?',  # é“¾æ¥]
        ]
        
        links = []
        duplicates = set()
        
        with open(self.txt_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                # å°è¯•æ‰€æœ‰æ­£åˆ™æ¨¡å¼
                for pattern in patterns:
                    matches = re.findall(pattern, line)
                    for match in matches:
                        # æ¸…ç†é“¾æ¥
                        clean_link = re.sub(r'[\[\]()]', '', match)
                        if (clean_link.startswith('https://wallhaven.cc/w/') and 
                            len(clean_link.split('/')[-1]) == 6 and 
                            clean_link not in duplicates):
                            links.append(clean_link)
                            duplicates.add(clean_link)
                            break  # æ‰¾åˆ°æœ‰æ•ˆé“¾æ¥å°±è·³å‡º
                
                # æ˜¾ç¤ºè§£æè¿‡ç¨‹ï¼ˆå‰5è¡Œï¼‰
                if line_num <= 5:
                    found = [m for pattern in patterns for m in re.findall(pattern, line)]
                    if found:
                        print(f"ğŸ“– ç¬¬{line_num}è¡Œè§£æ: {line[:60]}... -> {found[0][:50]}...")
        
        print(f"âœ… ä» {self.txt_file} è‡ªåŠ¨è§£æå‡º {len(links)} ä¸ªæœ‰æ•ˆé“¾æ¥")
        if len(links) == 0:
            print("ğŸ’¡ æç¤º: æ–‡ä»¶æ ¼å¼ç¤ºä¾‹:")
            print("  1. https://wallhaven.cc/w/l853yp")
            print("  2. [https://wallhaven.cc/w/ogy6zm](https://wallhaven.cc/w/ogy6zm)")
            print("  3. (https://wallhaven.cc/w/zpzd3j)")
        return links
    
    def get_image_info(self, wall_link):
        """è·å–å•ä¸ªå£çº¸åŸå›¾ä¿¡æ¯"""
        wallpaper_id = wall_link.split('/')[-1]
        try:
            api_url = f"https://wallhaven.cc/api/v1/w/{wallpaper_id}"
            resp = requests.get(api_url, headers=self.headers, timeout=10)
            if resp.status_code == 200:
                data = resp.json()['data']
                return wallpaper_id, data['path']
        except:
            pass
        return wallpaper_id, None
    
    def download_image(self, wall_link):
        """ä¸‹è½½å•ä¸ªå£çº¸"""
        wallpaper_id, img_url = self.get_image_info(wall_link)
        if not img_url:
            with self.lock:
                self.fail_count += 1
            return False
        
        try:
            img_resp = requests.get(img_url, headers=self.headers, 
                                  stream=True, timeout=30)
            if img_resp.status_code == 200:
                ext = img_url.split('.')[-1].split('?')[0]
                filename = f"{wallpaper_id}.{ext}"
                filepath = os.path.join(self.save_dir, filename)
                
                with open(filepath, 'wb') as f:
                    for chunk in img_resp.iter_content(8192):
                        f.write(chunk)
                
                size_mb = img_resp.headers.get('content-length', 0)
                size_mb = float(size_mb) / 1024 / 1024 if size_mb else 0
                
                with self.lock:
                    self.success_count += 1
                    self.print_progress(wallpaper_id, size_mb, filename)
                
                img_resp.close()
                del img_resp
                gc.collect()
                return True
        except:
            pass
        
        with self.lock:
            self.fail_count += 1
        return False
    
    def print_progress(self, wallpaper_id, size_mb, filename):
        """ç¾åŒ–è¿›åº¦è¾“å‡º"""
        process = psutil.Process()
        mem_mb = process.memory_info().rss / 1024 / 1024
        
        sys.stdout.write(f"\rğŸ¨ [{self.success_count:3d}/{self.total:3d}] "
                        f"{wallpaper_id} ({size_mb:5.1f}MB) "
                        f"ğŸ’¾{self.fail_count} | "
                        f"ğŸ§ {mem_mb:4.0f}MB")
        sys.stdout.flush()
    
    def monitor_memory(self):
        """å†…å­˜ç›‘æ§çº¿ç¨‹"""
        while getattr(self, 'running', False):
            process = psutil.Process()
            mem_mb = process.memory_info().rss / 1024 / 1024
            if mem_mb > 3000:
                gc.collect()
                print(f"\nğŸ§¹ å†…å­˜æ¸…ç†: {mem_mb:.0f}MB -> ", end="")
            time.sleep(5)
    
    def download(self):
        """å¤šçº¿ç¨‹æ‰¹é‡ä¸‹è½½ä¸»å‡½æ•°"""
        print("ğŸš€ Wallhaven å¤šçº¿ç¨‹æ‰¹é‡ä¸‹è½½å™¨ (æ™ºèƒ½è§£æç‰ˆ)")
        print("=" * 60)
        
        links = self.load_links()
        if not links:
            return
        
        self.total = len(links)
        self.running = True
        os.makedirs(self.save_dir, exist_ok=True)
        
        mem_thread = threading.Thread(target=self.monitor_memory, daemon=True)
        mem_thread.start()
        
        print(f"\nâš™ï¸  é…ç½®: {self.max_workers}çº¿ç¨‹ | "
              f"ç›®æ ‡: {self.total}å¼  | "
              f"ä¿å­˜: {os.path.abspath(self.save_dir)}")
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½...")
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(self.download_image, link) for link in links]
            
            with tqdm(total=self.total, desc="è¿›åº¦", 
                     bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]") as pbar:
                for future in as_completed(futures):
                    pbar.update(1)
        
        self.running = False
        
        print("\n" + "=" * 60)
        print(f"ğŸ‰ ä¸‹è½½å®Œæˆ!")
        print(f"âœ… æˆåŠŸ: {self.success_count}/{self.total}")
        print(f"âŒ å¤±è´¥: {self.fail_count}")
        print(f"ğŸ“ ä¿å­˜: {os.path.abspath(self.save_dir)}")
        gc.collect()

# ä¸€é”®ä½¿ç”¨
if __name__ == "__main__":
    downloader = WallhavenBatchDownloader(
        txt_file="wallhaven_hot_P20.txt",  # ä½ çš„åŸå§‹æ–‡ä»¶
        save_dir="ultra_hd_wallpapers",
        max_workers=4
    )
    downloader.download()
